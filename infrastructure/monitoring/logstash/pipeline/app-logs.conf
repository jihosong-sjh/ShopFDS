# Logstash Pipeline Configuration for ShopFDS Application Logs
# Purpose: Parse and forward FastAPI structured logs to Elasticsearch

input {
  # Beats input (for Filebeat, if used in future)
  beats {
    port => 5044
    codec => json
  }

  # HTTP input (for direct application logging)
  http {
    port => 8080
    codec => json
  }

  # TCP input (for traditional syslog-style logs)
  tcp {
    port => 5000
    codec => json_lines
  }
}

filter {
  # Parse JSON logs
  if [message] =~ /^\{/ {
    json {
      source => "message"
      target => "parsed"
    }
    
    # Move parsed fields to root level
    if [parsed] {
      ruby {
        code => "
          event.get('parsed').each { |k, v|
            event.set(k, v)
          }
        "
      }
      mutate {
        remove_field => ["parsed"]
      }
    }
  }

  # Grok pattern for FastAPI access logs
  grok {
    match => {
      "message" => [
        "%{IPORHOST:client_ip} - - \[%{HTTPDATE:timestamp}\] \"%{WORD:http_method} %{URIPATHPARAM:request_path} HTTP/%{NUMBER:http_version}\" %{NUMBER:status_code:int} %{NUMBER:response_size:int}",
        "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:message}"
      ]
    }
    overwrite => [ "message" ]
  }

  # Parse timestamp
  date {
    match => [ "timestamp", "ISO8601", "dd/MMM/yyyy:HH:mm:ss Z" ]
    target => "@timestamp"
  }

  # Add service name if not present
  if ![service] {
    if [log][file][path] =~ "ecommerce" {
      mutate { add_field => { "service" => "ecommerce" } }
    } else if [log][file][path] =~ "fds" {
      mutate { add_field => { "service" => "fds" } }
    } else if [log][file][path] =~ "ml-service" {
      mutate { add_field => { "service" => "ml-service" } }
    } else if [log][file][path] =~ "admin-dashboard" {
      mutate { add_field => { "service" => "admin-dashboard" } }
    } else {
      mutate { add_field => { "service" => "unknown" } }
    }
  }

  # Add environment tag
  if ![environment] {
    mutate { add_field => { "environment" => "development" } }
  }

  # Normalize log level
  if [level] {
    mutate {
      uppercase => [ "level" ]
    }
  }

  # Add geo IP information for client IPs
  if [client_ip] {
    geoip {
      source => "client_ip"
      target => "geoip"
    }
  }

  # Remove unnecessary fields
  mutate {
    remove_field => [ "host", "agent", "log", "ecs", "input" ]
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["${ELASTICSEARCH_HOST:elasticsearch:9200}"]
    index => "shopfds-%{service}-%{+YYYY.MM.dd}"
    document_type => "_doc"
    
    # Template management
    manage_template => true
    template_name => "shopfds"
    template_overwrite => false
  }

  # Debug output (comment out in production)
  # stdout { codec => rubydebug }
}
